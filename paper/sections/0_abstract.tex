Street network analysis provides insights into the emergent structure of streets and the potential ramifications of spatial interventions due to associations with pedestrian movement and intensities of land uses. However, the application of street network analysis in urban planning practice presents a complex historical trajectory with nuanced distinctions in representations, methodologies, and formulations. This can lead to ambiguity in usage over time, presenting a challenge to reproducibility and the generalisation of findings.

This paper notes a divergence between commonly cited formulations for closeness centrality (\emph{Normalised Closeness}) and the form of closeness favoured by computational packages (\emph{Improved Closeness}). We hypothesise that this arises due to a widespread shift to localised forms of network analysis (based on distance thresholds), which causes \emph{Normalised Closeness} to behave counter-intuitively.  Using open datasets and an openly reproducible workflow for Madrid, Spain, we show empirically that \emph{Normalised Closeness} is weakly associated with land-use intensities and trip origin-destinations for localised network analysis, and behaves contrary to \emph{Harmonic Closeness} and \emph{Improved Closeness} which show robust associations.

We clarify the context of this methodological misunderstanding and advocate for the use of openly reproducible reference workflows and datasets to aid with reproducibility and to control for differences that might otherwise be attributable to variations in datasets, formulations, and network representations.
